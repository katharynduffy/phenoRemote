---
title: "EVI_appeears_cache_tasks"
author: "K. Enns"
date: "2/28/2018"
output: html_document
---

### Creates a dataframe out of all of the tasks submitted to AppEEARS under your account
```{r}
# devtools::install_github("ennsk/AppEEARS4R")
library(jsonlite)
library(appeears)
library(httr)

username = ''
password = ''

token_response = appeears::appeears_start_session(username,password)
```

### Creates a dataframe out of all of the tasks submitted to AppEEARS under your account
```{r}
token         = paste("Bearer", token_response$token)
response      = GET("https://lpdaacsvc.cr.usgs.gov/appeears/api/task", add_headers(Authorization = token))
task_response = prettify(jsonlite::toJSON(content(response), auto_unbox = TRUE))
tasks = jsonlite::fromJSON(txt=task_response)
# tasks = tasks %>% distinct(task_id,task_name)
tasks
```
### Pullin in dataframe of phenocam rois
```{r}
rois      = jsonlite::fromJSON('https://phenocam.sr.unh.edu/api/roilists/?format=json&limit=2000')
roi_files = rois$results
roi_files
```

### parse through the appeears data frame of task requests and pull out all the EVI tasks.
```{r}
phenocams = unique(roi_files$site)
print (length(phenocams))

tasks_ndvi   = tasks[grep('_EVI_MOD13Q1_v6', tasks$task_name), ]
tasks_ndvi
task_sites   = unique(as.character(strsplit(tasks_ndvi$task_name, '_EVI_MOD13Q1_v6')))
print (task_sites)
print (length(task_sites))


```

### check for missing sites to submit to appeears
```{r}
m = match(phenocams, task_sites)
missing_sites = phenocams[is.na(m)]
print (paste0('Missing Sites:  ',missing_sites))
```

### Submitting tasks to AppEEARS - Be careful it's what you want.  Run code in test mode first
If you want to submit some tasks to AppEEARS use this function
```{r}
### Be careful here
source('/users/kenns/projects/r/apis/phenosynth/notebooks/appeears_data_production/submit_appeears_tasks.R')

# Test run (should raise error if there are no missing_sites to add a AppEEARS task for)
submit_appeears_tasks(appeears_token=token, roi_sites=missing_sites, data_layer='EVI', test=TRUE)

# Real run
# submit_appeears_tasks(appeears_token=token, roi_sites=missing_sites, data_layer='EVI', test=FALSE)
```

### Cache out appeears task into a df that Pheno-synth can use as a key to download associated EVI data for selected phenocam site (make sure they have all finished downloading, see tasks$status)
```{r}
evi_tasks   = tasks[grep('_EVI_MOD13Q1_v6', tasks$task_name), ]
evi_sites   = unique(evi_tasks$task_name)

sites = c()
for (x in c(1:length(evi_sites))){
  task = evi_tasks$task_name[x]
  site = strsplit(task, split = '_', fixed=TRUE)[[1]][1]
  if (site == 'HF'){
    site = paste0(site, '_Vivotek')
  }
  sites = c(sites, site)
}

headers = names(evi_tasks)

cache_df = data.frame(matrix(vector(), 0, 5,
                dimnames=list(c(), headers[c(4,5,7,10,11)])),
                stringsAsFactors=F)

for (x in c(1:length(sites))){
  print (sprintf('SITE: %s -----------------------------------', sites[x]))
  site_name   = sites[x]
  real_task_name = paste0(site_name, '_EVI_MOD13Q1_v6')
  print(real_task_name)
  
  site_rows   = evi_tasks[grep(real_task_name, evi_tasks$task_name), ]
  
  add_row = site_rows[,c(4,5,7,10,11)]
  cache_df = rbind(cache_df, add_row)
}

cache_df = cache_df %>% distinct(task_id, task_name, updated)

n_occur_    = data.frame(table(cache_df$task_name))
duplicates_ = n_occur_[n_occur_$Freq > 1,]
duplicates_ = as.character(duplicates_$Var1)
duplicates_
```

### Cache out the dataframe we just created above (cache_df)
```{r}
saveRDS(cache_df, file = '/users/kenns/projects/r/apis/phenosynth/www/cache_df_evi.df')
```

### Load in file
```{r}
evi_df = readRDS(file = '/users/kenns/projects/r/apis/phenosynth/www/cache_df_evi.df')
```

#### ---------
#### Extras :: Check for missing tasks, Bulk Delete
Qc tasks against phenocam api list to find missing tasks for appeears to re-submit
```{r}

evi_tasks   = tasks[grep('_EVI_MOD13Q1_v6', tasks$task_name), ]
evi_sites   = evi_tasks$task_name

sites = c()
for (x in c(1:length(evi_sites))){
  task = evi_tasks$task_name[x]
  site = strsplit(task, split = '_', fixed=TRUE)[[1]][1]
  sites = c(sites, site)
}

phenocams = unique(roi_files$site)
tasks_sites = unique(sites)

d = sites[duplicated(sites)]
d

length(sites)
length(tasks_sites)

length(phenocams)
length(tasks_sites)

sites_to_download = setdiff(phenocams, tasks_sites)
sites_to_download
length(sites_to_download)

n_occur    = data.frame(table(evi_tasks$task_name))
duplicates = n_occur[n_occur$Freq > 1,]
duplicates = as.character(duplicates$Var1)
duplicates
```

### Bulk delete duplicates  

```{r}
# for (site in duplicates){
#   rows = subset(evi_tasks, evi_tasks$task_name == site)
#   rows = rows[order(as.Date(rows$created)),]
#   row_to_remove = rows[1,]
#   print (rows)
# 
#   task_id <- row_to_remove$task_id
#   task_id
#   print (task_id)
#   response <- DELETE(paste("https://lpdaacsvc.cr.usgs.gov/appeears/api/task/", task_id, sep = ""), add_headers(Authorization = token))
#   response$status_code
#   print (response$status_code)
# }

```
